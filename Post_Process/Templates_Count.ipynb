{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "train_file = \"D:/Jupyter/data/dataset/perspective_stances/train.tsv\"\n",
    "\n",
    "df = pd.read_csv(train_file, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_match(matcher, doc, id, matches):\n",
    "    print(nlp.vocab.strings[match_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "737"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"lower\")\n",
    "matcher.add(\"not\", None, nlp(\"not\"), nlp(\"n't\"))\n",
    "matcher.add(\"can't\", None, nlp(\"can't\"))\n",
    "\n",
    "\n",
    "matcher_positive = PhraseMatcher(nlp.vocab, attr=\"ORTH\")\n",
    "matcher_positive.add(\"type\", None, nlp(\"is a type of\"), nlp(\"are a type of\") )\n",
    "matcher_positive.add(\"imply\", None, nlp(\"implies\") )\n",
    "matcher_positive.add(\"same\", None, nlp(\"is the same as \"), nlp(\"are the same as \") )\n",
    "matcher_positive.add(\"rephrase\", None, nlp(\" is a rephrasing of\") )\n",
    "matcher_positive.add(\"form\", None, nlp(\"is a another form of\"))\n",
    "matcher_positive.add(\"synonym\", None, nlp(\" is synonymous with\"))\n",
    "matcher_positive.add(\"can_be\", None, nlp(\"can be\"))\n",
    "\n",
    "\n",
    "matcher_positive.add(\"much\", None, nlp(\"much\"), nlp(\"Much\"))\n",
    "matcher_positive.add(\"little\", None, nlp(\"little\"), nlp(\"Little\"))\n",
    "matcher_positive.add(\"more\", None, nlp(\"more\"), nlp(\"More\"))\n",
    "matcher_positive.add(\"less\", None, nlp(\"less\"), nlp(\"Less\"))\n",
    "\n",
    "\n",
    "matcher_positive.add(\"fore_synonym\", None, nlp(\"are synonyms\"), nlp(\"are synonymous\"), nlp(\"is the same thing\"), nlp(\"are the same thing\") )\n",
    "matcher_positive.add(\"then\", None, nlp(\"then\") )\n",
    "matcher_positive.add(\"so\", None, nlp(\"so\") )\n",
    "matcher_positive.add(\"must_be\", None, nlp(\"must be\"))\n",
    "matcher_positive.add(\"hasto\", None, nlp(\"has to be\"))\n",
    "matcher_positive.add(\"is_are\", None, nlp(\"is\"), nlp(\"are\"), nlp(\"Are\"), nlp(\"ARE\"))\n",
    "\n",
    "matcher_positive.add(\"to\", None, nlp(\"to\"))\n",
    "matcher_positive.add(\"To\", None, nlp(\"To\"))\n",
    "matcher_positive.add(\"increase\", None, nlp(\"increase\"), nlp(\"increases\"), nlp(\"Increase\"))\n",
    "\n",
    "matcher_positive.add(\"should\", None, nlp(\"should\"), nlp(\"Should\") )\n",
    "matcher_positive.add(\"would\", None, nlp(\"would\"), nlp(\"Would\"))\n",
    "matcher_positive.add(\"could\", None, nlp(\"could\"), nlp(\"Could\"))\n",
    "matcher_positive.add(\"may\", None, nlp(\"may\"), nlp(\"May\"))\n",
    "matcher_positive.add(\"will\", None, nlp(\"will\"), nlp(\"Will\"))\n",
    "matcher_positive.add(\"can\", None, nlp(\"can\"), nlp(\"Can\"))\n",
    "matcher_positive.add(\"might\", None, nlp(\"might\"), nlp(\"Might\"))\n",
    "matcher_positive.add(\"must\", None, nlp(\"must\"), nlp(\"Must\"), nlp(\"MUST\"))\n",
    "\n",
    "matcher_positive.add(\"encourage\", None, nlp(\"encourage\"), nlp(\"encourages\"), nlp(\"Encourage\"), nlp(\"Encourages\"))\n",
    "\n",
    "matcher_positive.add(\"n’t\", None, nlp(\"n’t\"))\n",
    "matcher_positive.add(\"was_were\", None, nlp(\"was\"), nlp(\"were\"))\n",
    "matcher_positive.add(\"raise\", None, nlp(\"raise\"), nlp(\"raises\"), nlp(\"Raise\"), nlp(\"raising\"), nlp(\"Raising\"))\n",
    "matcher_positive.add(\"better\", None, nlp(\"better\"), nlp(\"Better\"))\n",
    "matcher_positive.add(\"benefit\", None, nlp(\"benefit\"), nlp(\"benefits\"), nlp(\"Benefit\"), nlp(\"Benefits\"))\n",
    "matcher_positive.add(\"lack\", None, nlp(\"lack\"), nlp(\"lacks\"), nlp(\"Lack\"), nlp(\"Lacks\"))\n",
    "matcher_positive.add(\"nothing\", None, nlp(\"nothing\"), nlp(\"Nothing\"))\n",
    "matcher_positive.add(\"positive\", None, nlp(\"positive\"),nlp(\"Positive\"))\n",
    "matcher_positive.add(\"negative\", None, nlp(\"negative\"), nlp(\"Negative\"))\n",
    "matcher_positive.add(\"have\", None, nlp(\"have\"),nlp(\"Have\"))\n",
    "matcher_positive.add(\"has\", None, nlp(\"has\"), nlp(\"Has\"))\n",
    "matcher_positive.add(\"reduce\", None, nlp(\"reduce\"), nlp(\"Reduce\"), nlp(\"reduces\"), nlp(\"Reduces\"), nlp(\"Reduced\"), nlp(\"reduced\"))\n",
    "matcher_positive.add(\"increase\", None, nlp(\"increase\"), nlp(\"Increase\"), nlp(\"increases\"), nlp(\"Increases\"), nlp(\"increased\"), nlp(\"Increased\"))\n",
    "matcher_positive.add(\"without\", None, nlp(\"without\"), nlp(\"Without\"))\n",
    "matcher_positive.add(\"against\", None, nlp(\"against\"), nlp(\"Against\"))\n",
    "matcher_positive.add(\"need\", None, nlp(\"need\"), nlp(\"Need\"), nlp(\"needs\"), nlp(\"Needs\"), nlp(\"needed\"), nlp(\"Needed\"))\n",
    "matcher_positive.add(\"needed\", None, nlp(\"needed\"), nlp(\"Needed\"))\n",
    "matcher_positive.add(\"good\", None, nlp(\"good\"), nlp(\"Good\"))\n",
    "matcher_positive.add(\"bad\", None, nlp(\"bad\"), nlp(\"Bad\"))\n",
    "matcher_positive.add(\"support\", None, nlp(\"support\"), nlp(\"Support\"), nlp(\"supports\"), nlp(\"Supports\"), nlp(\"supported\"), nlp(\"Supported\"))\n",
    "matcher_positive.add(\"hurt_harm_damage\", None, nlp(\"hurt\"), nlp(\"hurts\"), nlp(\"harm\"), nlp(\"harms\"), nlp(\"Hurt\"), nlp(\"Hurts\"), nlp(\"Harm\"), nlp(\"Harms\"), nlp(\"HARM\"), nlp(\"damage\"), nlp(\"damages\"), nlp(\"Damage\"), nlp(\"Damages\"))\n",
    "matcher_positive.add(\"help\", None, nlp(\"help\"), nlp(\"Help\"), nlp(\"helps\"), nlp(\"Helps\"))\n",
    "matcher_positive.add(\"protect\", None, nlp(\"protect\"), nlp(\"Protect\"), nlp(\"protects\"), nlp(\"Protects\"), nlp(\"protecting\"), nlp(\"protected\"), nlp(\"Protecting\"), nlp(\"Protected\"))\n",
    "matcher_positive.add(\"cause\", None, nlp(\"cause\"), nlp(\"Cause\"), nlp(\"causes\"), nlp(\"Causes\"))\n",
    "matcher_positive.add(\"allow\", None, nlp(\"allow\"), nlp(\"Allow\"), nlp(\"allows\"), nlp(\"Allows\"))\n",
    "matcher_positive.add(\"everyone\", None, nlp(\"everyone\"), nlp(\"Everyone\"))\n",
    "matcher_positive.add(\"deserve\", None, nlp(\"deserve\"), nlp(\"Deserve\"), nlp(\"deserves\"), nlp(\"Deserves\"), nlp(\"deserved\"), nlp(\"Deserved\"))\n",
    "\n",
    "\n",
    "opposite = []\n",
    "count_cant=0\n",
    "count_not=0\n",
    "count_type=0\n",
    "count_imply=0\n",
    "count_same=0\n",
    "count_rephrase=0\n",
    "count_form=0\n",
    "count_synonym=0\n",
    "count_canbe=0\n",
    "count_much=0\n",
    "count_little=0\n",
    "count_more=0\n",
    "count_less=0\n",
    "count_fore_synonym=0\n",
    "count_then=0\n",
    "count_so=0\n",
    "count_must_be=0\n",
    "count_has_to=0\n",
    "count_is_are=0\n",
    "count_to=0\n",
    "count_To=0\n",
    "count_increase=0\n",
    "count_should=0\n",
    "count_would=0\n",
    "count_could=0\n",
    "count_may=0\n",
    "count_will=0\n",
    "count_can=0\n",
    "count_might=0\n",
    "count_must=0\n",
    "count_encourage=0\n",
    "count_nt=0\n",
    "count_was_were=0\n",
    "count_raise=0\n",
    "count_better=0\n",
    "count_benefit=0\n",
    "count_lack=0\n",
    "count_nothing=0\n",
    "count_positive=0\n",
    "count_negative=0\n",
    "count_have=0\n",
    "count_has=0\n",
    "count_reduce=0\n",
    "count_increase=0\n",
    "count_without=0\n",
    "count_against=0\n",
    "count_need=0\n",
    "count_needed=0\n",
    "count_good=0\n",
    "count_bad=0\n",
    "count_support=0\n",
    "count_hurt_harm_damage=0\n",
    "count_help=0\n",
    "count_protect=0\n",
    "count_cause=0\n",
    "count_allow=0\n",
    "count_everyone=0\n",
    "count_deserve=0\n",
    "count_none=0\n",
    "\n",
    "for pers in df.perspective:\n",
    "    doc = nlp(pers)\n",
    "    matches = matcher(doc)\n",
    "    positive_matches = matcher_positive(doc)\n",
    "    if matches:\n",
    "        for match_id, start, end in matches:\n",
    "            rule_id = nlp.vocab.strings[match_id]\n",
    "            if rule_id == \"can't\":\n",
    "                new_seq = str(doc[0:start-1])+\" can \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_cant+=1\n",
    "                break\n",
    "            elif rule_id == \"not\":\n",
    "                if str(doc[start-1:start]) == \"ca\":\n",
    "                    continue\n",
    "                else:\n",
    "                    new_seq = str(doc[0:start])+\" \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_not += 1\n",
    "                    break\n",
    "    elif positive_matches:\n",
    "        for match_id, start, end in positive_matches:\n",
    "            rule_id = nlp.vocab.strings[match_id]\n",
    "            if rule_id == \"type\":\n",
    "                if doc[start:end][0] == \"is\":\n",
    "                    new_seq = str(doc[0:start])+\" is not a type of \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_type +=1\n",
    "                    break\n",
    "                elif doc[start:end][0] == \"are\":\n",
    "                    new_seq = str(doc[0:start])+\" are not a type of \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_type +=1\n",
    "                    break\n",
    "            elif rule_id == \"imply\":\n",
    "                if doc[start:end][0] == \"implies\":\n",
    "                    new_seq = str(doc[0:start])+\" does not imply \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_imply +=1\n",
    "                    break\n",
    "                elif doc[start:end][0] == \"imply\":\n",
    "                    new_seq = str(doc[0:start])+\" do not imply \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_imply +=1\n",
    "                    break\n",
    "            elif rule_id == \"same\":\n",
    "                if doc[start:end][0] == \"is\":\n",
    "                    new_seq = str(doc[0:start])+\" is not the same as \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_same +=1\n",
    "                    break\n",
    "                elif doc[start:end][0] == \"are\":\n",
    "                    new_seq = str(doc[0:start])+\" are not the same as \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_same +=1\n",
    "                    break\n",
    "            elif rule_id == \"rephrase\":\n",
    "                new_seq = str(doc[0:start])+\" is not a rephrasing of \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_rephrase +=1\n",
    "                break \n",
    "            elif rule_id == \"form\":\n",
    "                new_seq = str(doc[0:start])+\" is a another form of \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_form +=1\n",
    "                break \n",
    "            elif rule_id == \"synonym\":\n",
    "                new_seq = str(doc[0:start])+\" is not synonymous with \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_synonym +=1\n",
    "                break \n",
    "            elif rule_id == \"can_be\":\n",
    "                new_seq = str(doc[0:start])+\" can't be \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_canbe +=1\n",
    "                break \n",
    "            elif rule_id == \"fore_synonym\":\n",
    "                new_seq = str(doc[0:start])+\" are not synonymous\"\n",
    "                opposite.append(new_seq)\n",
    "                count_fore_synonym +=1\n",
    "                break \n",
    "            elif rule_id == \"then\":\n",
    "                new_seq = str(doc[0:start])+\" doesn't mean \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_then +=1\n",
    "                break \n",
    "            elif rule_id == \"so\":\n",
    "                new_seq = str(doc[0:start])+\" does not mean \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_so +=1\n",
    "                break \n",
    "            elif rule_id == \"must_be\":\n",
    "                new_seq = str(doc[0:start])+\" needn't be \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_must_be +=1\n",
    "                break \n",
    "            elif rule_id == \"hasto\":\n",
    "                new_seq = str(doc[0:start])+\" doesn't have to be\"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_has_to +=1\n",
    "                break\n",
    "            elif rule_id == \"much\":\n",
    "                if str(doc[start:end][0]) == \"Much\":\n",
    "                    new_seq = str(\"Little \"+str(doc[end:]))\n",
    "                    opposite.append(new_seq)\n",
    "                    count_much +=1\n",
    "                    break\n",
    "                elif str(doc[start:end][0]) == \"much\":\n",
    "                    new_seq = str(doc[0:start])+\" little \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_much +=1\n",
    "                    break\n",
    "            elif rule_id == \"little\":\n",
    "                if str(doc[start:end][0]) == \"Little\":\n",
    "                    new_seq = str(\"Much \"+str(doc[end:]))\n",
    "                    opposite.append(new_seq)\n",
    "                    count_little +=1\n",
    "                    break\n",
    "                elif str(doc[start:end][0]) == \"little\":\n",
    "                    new_seq = str(doc[0:start])+\" much \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_little +=1\n",
    "                    break\n",
    "            elif rule_id == \"more\":\n",
    "                if str(doc[start:end][0]) == \"More\":\n",
    "                    new_seq = str(\"Less \"+str(doc[end:]))\n",
    "                    opposite.append(new_seq)\n",
    "                    count_more +=1\n",
    "                    break\n",
    "                elif str(doc[start:end][0]) == \"more\":\n",
    "                    new_seq = str(doc[0:start])+\" less \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_more +=1\n",
    "                    break\n",
    "            elif rule_id == \"less\":\n",
    "                if str(doc[start:end][0]) == \"Less\":\n",
    "                    new_seq = str(\"More \"+str(doc[end:]))\n",
    "                    opposite.append(new_seq)\n",
    "                    count_less +=1\n",
    "                    break\n",
    "                elif str(doc[start:end][0]) == \"less\":\n",
    "                    new_seq = str(doc[0:start])+\" more \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_less +=1\n",
    "                    break\n",
    "            elif rule_id == \"is_are\":\n",
    "                if str(doc[start:end][0]) == \"is\":\n",
    "                    new_seq = str(doc[0:start])+\" is not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_is_are +=1\n",
    "                    break\n",
    "                elif str(doc[start:end][0]) == \"are\":\n",
    "                    new_seq = str(doc[0:start])+\" are not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_is_are +=1\n",
    "                    break\n",
    "                elif str(doc[start:end][0]) == \"Are\":\n",
    "                    new_seq = str(doc[0:start])+\" are not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_is_are +=1\n",
    "                    break\n",
    "                elif str(doc[start:end][0]) == \"ARE\":\n",
    "                    new_seq = str(doc[0:start])+\" are not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_is_are +=1\n",
    "                    break\n",
    "            elif rule_id == \"to\":\n",
    "                new_seq = str(doc[0:start])+\" not to \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_to +=1\n",
    "                break\n",
    "            elif rule_id == \"To\":\n",
    "                new_seq = str(doc[0:start])+\" Not to \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_To +=1\n",
    "                break\n",
    "            elif rule_id == \"increase\":\n",
    "                new_seq = str(doc[0:start])+\" decrease \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_increase +=1\n",
    "                break\n",
    "            elif rule_id == \"should\":\n",
    "                new_seq = str(doc[0:start])+\" should not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_should +=1\n",
    "                break\n",
    "            elif rule_id == \"would\":\n",
    "                new_seq = str(doc[0:start])+\" would not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_would +=1\n",
    "                break\n",
    "            elif rule_id == \"could\":\n",
    "                new_seq = str(doc[0:start])+\" could not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_could +=1\n",
    "                break\n",
    "            elif rule_id == \"may\":\n",
    "                new_seq = str(doc[0:start])+\" may not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_may +=1\n",
    "                break\n",
    "            elif rule_id == \"will\":\n",
    "                new_seq = str(doc[0:start])+\" will not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_will +=1\n",
    "                break\n",
    "            elif rule_id == \"can\":\n",
    "                new_seq = str(doc[0:start])+\" can not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_can +=1\n",
    "                break\n",
    "            elif rule_id == \"might\":\n",
    "                new_seq = str(doc[0:start])+\" might not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_might +=1\n",
    "                break\n",
    "            elif rule_id == \"must\":\n",
    "                new_seq = str(doc[0:start])+\" must not \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_must +=1\n",
    "                break\n",
    "            elif rule_id == \"encourage\":\n",
    "                new_seq = str(doc[0:start])+\" discourage \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_encourage +=1\n",
    "                break\n",
    "            elif rule_id == \"n’t\":\n",
    "                new_seq = str(doc[0:start])+\" \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_nt +=1\n",
    "                break\n",
    "            elif rule_id == \"was_were\":\n",
    "                if str(doc[start:end][0]) == \"was\":\n",
    "                    new_seq = str(doc[0:start])+\" was not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_was_were +=1\n",
    "                    break\n",
    "                elif str(doc[start:end][0]) == \"were\":\n",
    "                    new_seq = str(doc[0:start])+\" were not \"+str(doc[end:])\n",
    "                    opposite.append(new_seq)\n",
    "                    count_was_were +=1\n",
    "                    break\n",
    "            elif rule_id == \"raise\":\n",
    "                new_seq = str(doc[0:start])+\" lower \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_raise +=1\n",
    "                break\n",
    "            elif rule_id == \"better\":\n",
    "                new_seq = str(doc[0:start])+\" worse \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_better +=1\n",
    "                break\n",
    "            elif rule_id == \"benefit\":\n",
    "                new_seq = str(doc[0:start])+\" harm \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_benefit +=1\n",
    "                break\n",
    "            elif rule_id == \"lack\":\n",
    "                new_seq = str(doc[0:start])+\" glut \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_lack +=1\n",
    "                break\n",
    "            elif rule_id == \"nothing\":\n",
    "                new_seq = str(doc[0:start])+\" something \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_nothing +=1\n",
    "                break\n",
    "            elif rule_id == \"positive\":\n",
    "                new_seq = str(doc[0:start])+\" negative \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_positive +=1\n",
    "                break\n",
    "            elif rule_id == \"negative\":\n",
    "                new_seq = str(doc[0:start])+\" positive \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_negative +=1\n",
    "                break\n",
    "            elif rule_id == \"have\":\n",
    "                new_seq = str(doc[0:start])+\" don't have \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_have +=1\n",
    "                break\n",
    "            elif rule_id == \"has\":\n",
    "                new_seq = str(doc[0:start])+\" doesn't have \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_has +=1\n",
    "                break\n",
    "            elif rule_id == \"reduce\":\n",
    "                new_seq = str(doc[0:start])+\" increase \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_reduce +=1\n",
    "                break\n",
    "            elif rule_id == \"increase\":\n",
    "                new_seq = str(doc[0:start])+\" decrease \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_increase +=1\n",
    "                break\n",
    "            elif rule_id == \"without\":\n",
    "                new_seq = str(doc[0:start])+\" with \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_without +=1\n",
    "                break\n",
    "            elif rule_id == \"against\":\n",
    "                new_seq = str(doc[0:start])+\" for \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_against +=1\n",
    "                break\n",
    "            elif rule_id == \"needed\":\n",
    "                new_seq = str(doc[0:start])+\" not needed \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_needed +=1\n",
    "                break\n",
    "            elif rule_id == \"need\":\n",
    "                new_seq = str(doc[0:start])+\" don't need \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_need +=1\n",
    "                break\n",
    "            elif rule_id == \"good\":\n",
    "                new_seq = str(doc[0:start])+\" bad \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_good +=1\n",
    "                break\n",
    "            elif rule_id == \"bad\":\n",
    "                new_seq = str(doc[0:start])+\" good \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_bad +=1\n",
    "                break\n",
    "            elif rule_id == \"support\":\n",
    "                new_seq = str(doc[0:start])+\" oppose \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_support +=1\n",
    "                break\n",
    "            elif rule_id == \"hurt_harm_damage\":\n",
    "                new_seq = str(doc[0:start])+\" protect \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_hurt_harm_damage +=1\n",
    "                break\n",
    "            elif rule_id == \"help\":\n",
    "                new_seq = str(doc[0:start])+\" spoil \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_help +=1\n",
    "                break\n",
    "            elif rule_id == \"protect\":\n",
    "                new_seq = str(doc[0:start])+\" destroy \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_protect +=1\n",
    "                break\n",
    "            elif rule_id == \"cause\":\n",
    "                new_seq = str(doc[0:start])+\" casue no \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_cause +=1\n",
    "                break\n",
    "            elif rule_id == \"allow\":\n",
    "                new_seq = str(doc[0:start])+\" disallow \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_allow +=1\n",
    "                break\n",
    "            elif rule_id == \"everyone\":\n",
    "                new_seq = str(doc[0:start])+\" noone \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_everyone +=1\n",
    "                break\n",
    "            elif rule_id == \"deserve\":\n",
    "                new_seq = str(doc[0:start])+\" deserve no \"+str(doc[end:])\n",
    "                opposite.append(new_seq)\n",
    "                count_deserve +=1\n",
    "                break\n",
    "    else:\n",
    "        new_seq = None\n",
    "        opposite.append(new_seq)\n",
    "        count_none +=1\n",
    "# print(count_cant, count_not)\n",
    "\n",
    "# print(count_cant,\n",
    "# count_not,\n",
    "# count_type,\n",
    "# count_imply,\n",
    "# count_same,\n",
    "# count_rephrase,\n",
    "# count_form,\n",
    "# count_synonym,\n",
    "# count_canbe,\n",
    "# count_much,\n",
    "# count_little,\n",
    "# count_more,\n",
    "# count_less,\n",
    "# count_fore_synonym,\n",
    "# count_then,\n",
    "# count_so,\n",
    "# count_must_be,\n",
    "# count_has_to,\n",
    "# count_is_are,\n",
    "# count_to,\n",
    "# count_To,\n",
    "# count_increase,\n",
    "# count_should,\n",
    "# count_would,\n",
    "# count_could,\n",
    "# count_may,\n",
    "# count_will,\n",
    "# count_can,\n",
    "# count_might,\n",
    "# count_must,\n",
    "# count_encourage,\n",
    "# count_nt,\n",
    "# count_was_were,\n",
    "# count_raise,\n",
    "# count_better,\n",
    "# count_benefit,\n",
    "# count_lack,\n",
    "# count_nothing,\n",
    "# count_positive,\n",
    "# count_negative,\n",
    "# count_have,\n",
    "# count_has,\n",
    "# count_reduce,\n",
    "# count_increase,\n",
    "# count_without,\n",
    "# count_against,\n",
    "# count_need,\n",
    "# count_needed,\n",
    "# count_good,\n",
    "# count_bad,\n",
    "# count_support,\n",
    "# count_hurt_harm_damage,\n",
    "# count_help,\n",
    "# count_protect,\n",
    "# count_cause,\n",
    "# count_allow,\n",
    "# count_everyone,\n",
    "# count_deserve)\n",
    "print(len(opposite))\n",
    "count_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "737"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_none"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>claim</th>\n",
       "      <th>perspective</th>\n",
       "      <th>opposite_perspective</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male infant circumcision is tantamount to chil...</td>\n",
       "      <td>Parents have the right to use their best judgm...</td>\n",
       "      <td>Parents don't have the right to use their best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Male infant circumcision is tantamount to chil...</td>\n",
       "      <td>Parents have the right to make the decisions f...</td>\n",
       "      <td>Parents don't have the right to make the decis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>punishment should fit the criminal</td>\n",
       "      <td>It will cause less re-offenders.</td>\n",
       "      <td>It will not cause less re-offenders.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>punishment should fit the criminal</td>\n",
       "      <td>Adequate punishment reduces future offenses.</td>\n",
       "      <td>Adequate punishment increase future offenses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>punishment should fit the criminal</td>\n",
       "      <td>Just punishment will lead to less criminals re...</td>\n",
       "      <td>Just punishment will not lead to less criminal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7002</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internet access is a human right</td>\n",
       "      <td>Piracy is unlikely to be stopped without cutti...</td>\n",
       "      <td>Piracy is not unlikely to be stopped without c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internet access is a human right</td>\n",
       "      <td>These people are breaking the law and need to ...</td>\n",
       "      <td>These people are not breaking the law and need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7004</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internet access is a human right</td>\n",
       "      <td>Criminals deserve to be punished.</td>\n",
       "      <td>Criminals deserve no to be punished.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7005</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internet access is a human right</td>\n",
       "      <td>Illegal downloaders are breaking the law and d...</td>\n",
       "      <td>Illegal downloaders are not breaking the law a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7006</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Internet access is a human right</td>\n",
       "      <td>It is a big problem, too many people are file-...</td>\n",
       "      <td>It is not a big problem, too many people are f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6270 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label  x  y                                              claim  \\\n",
       "0         0  0  0  Male infant circumcision is tantamount to chil...   \n",
       "2         0  0  0  Male infant circumcision is tantamount to chil...   \n",
       "3         1  0  0                 punishment should fit the criminal   \n",
       "4         1  0  0                 punishment should fit the criminal   \n",
       "5         1  0  0                 punishment should fit the criminal   \n",
       "...     ... .. ..                                                ...   \n",
       "7002      0  0  0                   Internet access is a human right   \n",
       "7003      0  0  0                   Internet access is a human right   \n",
       "7004      0  0  0                   Internet access is a human right   \n",
       "7005      0  0  0                   Internet access is a human right   \n",
       "7006      0  0  0                   Internet access is a human right   \n",
       "\n",
       "                                            perspective  \\\n",
       "0     Parents have the right to use their best judgm...   \n",
       "2     Parents have the right to make the decisions f...   \n",
       "3                      It will cause less re-offenders.   \n",
       "4          Adequate punishment reduces future offenses.   \n",
       "5     Just punishment will lead to less criminals re...   \n",
       "...                                                 ...   \n",
       "7002  Piracy is unlikely to be stopped without cutti...   \n",
       "7003  These people are breaking the law and need to ...   \n",
       "7004                  Criminals deserve to be punished.   \n",
       "7005  Illegal downloaders are breaking the law and d...   \n",
       "7006  It is a big problem, too many people are file-...   \n",
       "\n",
       "                                   opposite_perspective  \n",
       "0     Parents don't have the right to use their best...  \n",
       "2     Parents don't have the right to make the decis...  \n",
       "3                  It will not cause less re-offenders.  \n",
       "4         Adequate punishment increase future offenses.  \n",
       "5     Just punishment will not lead to less criminal...  \n",
       "...                                                 ...  \n",
       "7002  Piracy is not unlikely to be stopped without c...  \n",
       "7003  These people are not breaking the law and need...  \n",
       "7004               Criminals deserve no to be punished.  \n",
       "7005  Illegal downloaders are not breaking the law a...  \n",
       "7006  It is not a big problem, too many people are f...  \n",
       "\n",
       "[6270 rows x 6 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"opposite_perspective\"] = opposite\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count_cant</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_not</th>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_type</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_imply</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_same</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_rephrase</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_form</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_synonym</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_canbe</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_much</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_little</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_more</th>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_less</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_fore_synonym</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_then</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_so</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_must_be</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_has_to</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_is_are</th>\n",
       "      <td>1697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_to</th>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_To</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_should</th>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_would</th>\n",
       "      <td>469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_could</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_may</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_will</th>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_can</th>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_might</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_must</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_encourage</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_nt</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_was_were</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_raise</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_better</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_benefit</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_lack</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_nothing</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_positive</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_negative</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_have</th>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_has</th>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_reduce</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_increase</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_without</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_against</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_need</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_needed</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_good</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_bad</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_support</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_hurt_harm_damage</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_help</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_protect</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_cause</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_allow</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_everyone</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_deserve</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           0\n",
       "count_cant                23\n",
       "count_not                961\n",
       "count_type                 0\n",
       "count_imply                0\n",
       "count_same                 0\n",
       "count_rephrase             0\n",
       "count_form                 0\n",
       "count_synonym              0\n",
       "count_canbe                0\n",
       "count_much                16\n",
       "count_little               4\n",
       "count_more               113\n",
       "count_less                24\n",
       "count_fore_synonym         0\n",
       "count_then                 1\n",
       "count_so                  10\n",
       "count_must_be              0\n",
       "count_has_to               0\n",
       "count_is_are            1697\n",
       "count_to                 513\n",
       "count_To                  40\n",
       "count_should             259\n",
       "count_would              469\n",
       "count_could               89\n",
       "count_may                 62\n",
       "count_will               337\n",
       "count_can                380\n",
       "count_might               13\n",
       "count_must                39\n",
       "count_encourage           20\n",
       "count_nt                  16\n",
       "count_was_were            65\n",
       "count_raise               32\n",
       "count_better              21\n",
       "count_benefit             50\n",
       "count_lack                20\n",
       "count_nothing              9\n",
       "count_positive            17\n",
       "count_negative             1\n",
       "count_have               237\n",
       "count_has                202\n",
       "count_reduce              30\n",
       "count_increase            42\n",
       "count_without             22\n",
       "count_against             16\n",
       "count_need                73\n",
       "count_needed               8\n",
       "count_good                22\n",
       "count_bad                 10\n",
       "count_support             26\n",
       "count_hurt_harm_damage    49\n",
       "count_help                46\n",
       "count_protect             29\n",
       "count_cause               48\n",
       "count_allow               60\n",
       "count_everyone            37\n",
       "count_deserve             12"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_df = pd.DataFrame([count_cant,\n",
    "count_not,\n",
    "count_type,\n",
    "count_imply,\n",
    "count_same,\n",
    "count_rephrase,\n",
    "count_form,\n",
    "count_synonym,\n",
    "count_canbe,\n",
    "count_much,\n",
    "count_little,\n",
    "count_more,\n",
    "count_less,\n",
    "count_fore_synonym,\n",
    "count_then,\n",
    "count_so,\n",
    "count_must_be,\n",
    "count_has_to,\n",
    "count_is_are,\n",
    "count_to,\n",
    "count_To,\n",
    "count_should,\n",
    "count_would,\n",
    "count_could,\n",
    "count_may,\n",
    "count_will,\n",
    "count_can,\n",
    "count_might,\n",
    "count_must,\n",
    "count_encourage,\n",
    "count_nt,\n",
    "count_was_were,\n",
    "count_raise,\n",
    "count_better,\n",
    "count_benefit,\n",
    "count_lack,\n",
    "count_nothing,\n",
    "count_positive,\n",
    "count_negative,\n",
    "count_have,\n",
    "count_has,\n",
    "count_reduce,\n",
    "count_increase,\n",
    "count_without,\n",
    "count_against,\n",
    "count_need,\n",
    "count_needed,\n",
    "count_good,\n",
    "count_bad,\n",
    "count_support,\n",
    "count_hurt_harm_damage,\n",
    "count_help,\n",
    "count_protect,\n",
    "count_cause,\n",
    "count_allow,\n",
    "count_everyone,\n",
    "count_deserve],index=[\"count_cant\",\n",
    "\"count_not\",\n",
    "\"count_type\",\n",
    "\"count_imply\",\n",
    "\"count_same\",\n",
    "\"count_rephrase\",\n",
    "\"count_form\",\n",
    "\"count_synonym\",\n",
    "\"count_canbe\",\n",
    "\"count_much\",\n",
    "\"count_little\",\n",
    "\"count_more\",\n",
    "\"count_less\",\n",
    "\"count_fore_synonym\",\n",
    "\"count_then\",\n",
    "\"count_so\",\n",
    "\"count_must_be\",\n",
    "\"count_has_to\",\n",
    "\"count_is_are\",\n",
    "\"count_to\",\n",
    "\"count_To\",\n",
    "\"count_should\",\n",
    "\"count_would\",\n",
    "\"count_could\",\n",
    "\"count_may\",\n",
    "\"count_will\",\n",
    "\"count_can\",\n",
    "\"count_might\",\n",
    "\"count_must\",\n",
    "\"count_encourage\",\n",
    "\"count_nt\",\n",
    "\"count_was_were\",\n",
    "\"count_raise\",\n",
    "\"count_better\",\n",
    "\"count_benefit\",\n",
    "\"count_lack\",\n",
    "\"count_nothing\",\n",
    "\"count_positive\",\n",
    "\"count_negative\",\n",
    "\"count_have\",\n",
    "\"count_has\",\n",
    "\"count_reduce\",\n",
    "\"count_increase\",\n",
    "\"count_without\",\n",
    "\"count_against\",\n",
    "\"count_need\",\n",
    "\"count_needed\",\n",
    "\"count_good\",\n",
    "\"count_bad\",\n",
    "\"count_support\",\n",
    "\"count_hurt_harm_damage\",\n",
    "\"count_help\",\n",
    "\"count_protect\",\n",
    "\"count_cause\",\n",
    "\"count_allow\",\n",
    "\"count_everyone\",\n",
    "\"count_deserve\"])\n",
    "\n",
    "template_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6270], dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(template_df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_df.to_excel(\"./experiment_output/templates_count_perspectives.xlsx\")\n",
    "template_df.to_csv(\"./experiment_output/templates_count_perspectives.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
